---
phase: 03-rag-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/server/lib/chroma.ts
  - src/server/lib/rag.ts
  - scripts/import-gemini-history.ts
autonomous: true
requirements: [RAG-01, RAG-02]

must_haves:
  truths:
    - "Gemini coaching export is parsed into workout-session-level chunks with metadata"
    - "Chunks are embedded with gemini-embedding-001 at 768 dimensions and stored in ChromaDB"
    - "Coaching profile data is embedded as a special chunk in the same collection"
    - "Semantic search returns relevant past sessions when queried"
  artifacts:
    - path: "src/server/lib/chroma.ts"
      provides: "ChromaDB client, GeminiEmbeddingFunction, getCollection helper"
      exports: ["getCollection", "embedder", "client", "COLLECTION_NAME"]
    - path: "src/server/lib/rag.ts"
      provides: "Retrieval with recency weighting, embed+store utility, metadata extraction"
      exports: ["retrieveRelevantSessions", "embedAndStore", "extractMetadata"]
    - path: "scripts/import-gemini-history.ts"
      provides: "One-time import: parse Gemini export, chunk by session, embed, store in ChromaDB"
  key_links:
    - from: "src/server/lib/chroma.ts"
      to: "ChromaDB server on port 8100"
      via: "ChromaClient HTTP connection"
      pattern: "new ChromaClient.*host.*port"
    - from: "src/server/lib/rag.ts"
      to: "src/server/lib/chroma.ts"
      via: "getCollection import"
      pattern: "import.*getCollection.*from.*chroma"
    - from: "scripts/import-gemini-history.ts"
      to: "src/server/lib/chroma.ts"
      via: "getCollection for batch add"
      pattern: "import.*getCollection.*from.*chroma"
---

<objective>
Build the ChromaDB integration layer and import the user's full Gemini coaching history as the seed knowledge base.

Purpose: This creates the persistent memory foundation -- the ChromaDB client, embedding function, retrieval utilities, and the one-time import that transforms 7 weeks of training history into searchable, session-level chunks enriched with exercise/muscle-group metadata.

Output: ChromaDB client module, RAG utility library, executed import script with all coaching history embedded and queryable.
</objective>

<execution_context>
@/home/mcook/.claude/get-shit-done/workflows/execute-plan.md
@/home/mcook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-rag-pipeline/03-RESEARCH.md
@.planning/phases/01-validation-and-foundation/01-01-SUMMARY.md
@scripts/test-chromadb.ts
@src/server/lib/gemini.ts
@data/gemini-export.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: ChromaDB client module and RAG utility library</name>
  <files>src/server/lib/chroma.ts, src/server/lib/rag.ts</files>
  <action>
Create `src/server/lib/chroma.ts`:
- Adapt the proven `GeminiEmbeddingFunction` from `scripts/test-chromadb.ts` (Phase 1), but use 768-dim embeddings with L2 normalization instead of 3072-dim (per research recommendation: 0.26% quality loss, 75% storage savings)
- Import `ai` from `./gemini.js` (existing Gemini client wrapper)
- Use `gemini-embedding-001` model (the only available embedding model -- `text-embedding-004` was shut down Jan 14 2026)
- Read CHROMA_HOST (default `localhost`) and CHROMA_PORT (default `8100`) from process.env
- Collection name: `coaching-history` with `hnsw:space: cosine` metadata
- Export: `getCollection()`, `embedder`, `client`, `COLLECTION_NAME`
- DO NOT use `@chroma-core/google-gemini` package (bundles old SDK, cannot use gemini-embedding-001)

Create `src/server/lib/rag.ts`:
- `retrieveRelevantSessions(query: string, topK?: number)`: Query ChromaDB with queryTexts, over-fetch 2x candidates, re-rank with recency weighting (0.7 * semantic similarity + 0.3 * time decay with 30-day half-life using `Math.exp(-daysSince / 30)`). Return top K results (default 5) with { id, document, snippet (first 800 chars), metadata, score }.
- `embedAndStore(userMessage: string, aiResponse: string, metadata: Record<string, unknown>)`: Concatenate user+AI text, generate deterministic ID (`live-{date}-msg-{hash}`), add to ChromaDB collection. Non-blocking pattern -- caller will catch errors.
- `extractMetadata(text: string)`: Keyword-based extraction of exercise names and muscle groups. Use exercise keywords list: squat, bench, deadlift, press, row, pull-up, dip, curl, lunge, bridge, plank, pushup, overhead press, floor press, inverted row, step-up. Map to muscle groups: chest, back, legs, shoulders, core. Return `{ exercises: string[], muscleGroups: string[] }`.
- `daysBetween(dateA: string, dateB: string)`: Helper for recency scoring.
- Add a `checkChromaHealth()` function that pings ChromaDB and returns boolean -- used by server startup for graceful degradation.
  </action>
  <verify>
Run `npx tsx -e "import { getCollection } from './src/server/lib/chroma.js'; const c = await getCollection(); console.log('Collection:', c.name); const count = await c.count(); console.log('Count:', count)"` -- should connect and show collection name. Ensure no TypeScript errors: `npx tsc --noEmit src/server/lib/chroma.ts src/server/lib/rag.ts`.
  </verify>
  <done>ChromaDB client connects on port 8100, getCollection returns the coaching-history collection, retrieveRelevantSessions and embedAndStore functions exist and export correctly, extractMetadata returns exercise/muscle-group tags from text.</done>
</task>

<task type="auto">
  <name>Task 2: Import Gemini coaching history into ChromaDB</name>
  <files>scripts/import-gemini-history.ts</files>
  <action>
Create `scripts/import-gemini-history.ts` that imports the full Gemini coaching export from `data/gemini-export.txt` into ChromaDB:

**Parsing:**
- Read the export file (6744 lines, 179 "You said" markers)
- Split on `^You said$` line markers to extract user-AI exchange pairs
- The first section before any "You said" is header content (title, URL, dates) -- skip it
- For each "You said" section: the user message is the text immediately after "You said" up to the first AI response, and the AI response is everything after until the next "You said" or EOF

**Session grouping (Claude's discretion on exact heuristics):**
- Group consecutive exchanges into workout sessions using:
  - Day/date references in text (e.g., "Monday:", "Workout A:", "Week 3 Day 1") signal new sessions
  - Messages requesting a new workout plan start new sessions
  - Messages reporting results from a completed workout start new sessions
  - Quick follow-ups ("update:", "actually", "one more thing") stay in the current session
- Each session becomes one chunk with all user+AI exchanges concatenated, preserving full conversation text (per user decision)

**Metadata enrichment:**
- Extract session date from text content (look for date patterns, day names, "Week X Day Y")
- Use `extractMetadata()` from rag.ts for exercise names and muscle groups
- Add `type: 'gemini-import'` to distinguish from live sessions
- Generate deterministic IDs: `gemini-import-{NNN}` (zero-padded index)

**Embedding:**
- Batch add to ChromaDB using collection.add() with documents, ids, and metadatas
- Add configurable delay between embedding API calls (default 100ms) to avoid rate limits
- If a session exceeds ~1800 tokens (leaving headroom for the 2048 input token limit), split into sub-chunks with 200-token overlap, prefixing each sub-chunk with the session date and topic
- Log progress: "Embedding chunk X/Y..."

**Features:**
- `--dry-run` flag: show chunk boundaries, token estimates, and metadata without actually embedding (per research recommendation for tuning heuristics)
- `--delay=N` flag: configurable delay in ms between embedding calls (default 100)
- After import, log collection count and sample query result for verification

**Also embed coaching profile as a special chunk:**
- Load the coaching profile from the database (or hardcode from known profile data if DB not available in script context)
- Create a chunk with id `coaching-profile` containing maxes, injuries, equipment, dietary constraints, preferences
- Add metadata: `type: 'profile', date: '{today}'`
- This lets the profile participate in semantic retrieval (per user decision to merge profile into RAG)
  </action>
  <verify>
Run `npx tsx scripts/import-gemini-history.ts --dry-run` -- should show chunk boundaries, session count, and metadata without embedding. Then run `npx tsx scripts/import-gemini-history.ts` to execute the full import. Verify with `npx tsx -e "import { getCollection } from './src/server/lib/chroma.js'; const c = await getCollection(); console.log('Count:', await c.count()); const r = await c.query({ queryTexts: ['What was my squat workout like?'], nResults: 3, include: ['documents', 'metadatas', 'distances'] }); console.log('Query results:', JSON.stringify(r.metadatas, null, 2))"` -- should return relevant squat-related sessions.
  </verify>
  <done>All Gemini coaching history is parsed into session-level chunks, embedded at 768 dimensions, and stored in ChromaDB. Dry-run mode works for inspection. Semantic search returns relevant past sessions. Coaching profile is embedded as a queryable chunk. Collection count matches expected chunk count.</done>
</task>

</tasks>

<verification>
1. ChromaDB collection `coaching-history` exists with all imported chunks (verify count > 0)
2. `--dry-run` shows reasonable session boundaries (not too granular, not too large)
3. Semantic query for "squat workout" returns squat-related sessions
4. Semantic query for "shoulder injury" returns sessions mentioning shoulder issues
5. Each chunk has metadata: date, exercises, muscleGroups, type
6. No TypeScript compilation errors in new files
</verification>

<success_criteria>
- ChromaDB client module connects reliably to port 8100
- Gemini export fully imported as session-level chunks with metadata
- Semantic retrieval returns contextually relevant results with recency weighting
- RAG utility functions (retrieve, embed, extract) are ready for integration in Plan 02
</success_criteria>

<output>
After completion, create `.planning/phases/03-rag-pipeline/03-01-SUMMARY.md`
</output>
