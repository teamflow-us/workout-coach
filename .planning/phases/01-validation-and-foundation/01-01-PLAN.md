---
phase: 01-validation-and-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/validate-export.ts
  - scripts/count-tokens.ts
  - scripts/test-chromadb.ts
  - data/gemini-export.txt
  - package.json
  - tsconfig.json
  - .env
  - .gitignore
autonomous: false
user_setup:
  - service: gemini
    why: "Token counting and embedding pipeline require Gemini API access"
    env_vars:
      - name: GEMINI_API_KEY
        source: "Google AI Studio -> Get API key (https://aistudio.google.com/app/apikey)"
  - service: gemini-export
    why: "Conversation data must be manually exported from Gemini web app"
    dashboard_config:
      - task: "Export Gemini conversation to data/gemini-export.txt"
        location: "gemini.google.com -> open the coaching mega-thread -> copy full conversation"

must_haves:
  truths:
    - "Gemini conversation export exists as a file and has been verified for completeness"
    - "Token count of the full conversation is measured with the Gemini API"
    - "RAG strategy is decided based on measured token count"
    - "ChromaDB accepts documents, generates Gemini embeddings, and returns semantic query results"
    - "Gemini structured JSON output produces a valid workout object from a Zod schema"
  artifacts:
    - path: "scripts/validate-export.ts"
      provides: "Export quality validation — checks first/last/middle sessions"
    - path: "scripts/count-tokens.ts"
      provides: "Token counting via Gemini API with RAG strategy recommendation"
    - path: "scripts/test-chromadb.ts"
      provides: "End-to-end ChromaDB + Gemini embedding + structured output test"
    - path: "data/gemini-export.txt"
      provides: "Exported Gemini coaching conversation"
  key_links:
    - from: "scripts/count-tokens.ts"
      to: "Gemini countTokens API"
      via: "@google/genai SDK"
      pattern: "ai\\.models\\.countTokens"
    - from: "scripts/test-chromadb.ts"
      to: "ChromaDB server on localhost:8000"
      via: "chromadb client + @chroma-core/google-gemini embedder"
      pattern: "ChromaClient.*GoogleGeminiEmbeddingFunction"
---

<objective>
Resolve the three critical unknowns blocking the rest of the project: (1) export and validate the Gemini coaching conversation, (2) measure its token count to decide the RAG strategy, and (3) prove the ChromaDB + Gemini embedding pipeline works end-to-end with structured JSON output.

Purpose: Everything downstream depends on knowing the data quality, data size, and that the embedding pipeline works. Without this, the architecture is built on assumptions.
Output: Validated export file, token count measurement, RAG strategy decision, working ChromaDB test script.
</objective>

<execution_context>
@/home/mcook/.claude/get-shit-done/workflows/execute-plan.md
@/home/mcook/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-validation-and-foundation/01-CONTEXT.md
@.planning/phases/01-validation-and-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize project and install validation dependencies</name>
  <files>package.json, tsconfig.json, .env, .gitignore</files>
  <action>
Initialize the Node.js project at the repo root:

1. Run `npm init -y` to create package.json. Set `"type": "module"` for ESM support.
2. Install dependencies:
   ```
   npm install @google/genai chromadb @chroma-core/google-gemini zod zod-to-json-schema dotenv
   npm install -D typescript @types/node tsx
   ```
3. Create tsconfig.json with:
   - `"target": "ES2022"`, `"module": "NodeNext"`, `"moduleResolution": "NodeNext"`
   - `"outDir": "./dist"`, `"rootDir": "."`
   - `"strict": true`, `"esModuleInterop": true`
   - `"include": ["src/**/*", "scripts/**/*"]`
4. Create .env with `GEMINI_API_KEY=` placeholder (user fills in the actual key).
5. Create .gitignore with: `node_modules/`, `.env`, `data/`, `dist/`, `*.db`, `chroma-data/`
6. Create empty `data/` and `scripts/` directories.

Do NOT install Hono, Drizzle, or React yet — those belong to Plan 01-02.
  </action>
  <verify>
`ls package.json tsconfig.json .env .gitignore` shows all four files exist.
`node -e "const p = JSON.parse(require('fs').readFileSync('package.json','utf8')); console.log(p.type)"` prints `module`.
`npm ls @google/genai chromadb` shows both installed without errors.
  </verify>
  <done>Project initialized with ESM, validation dependencies installed, .env and .gitignore configured.</done>
</task>

<task type="checkpoint:human-action" gate="blocking">
  <name>Task 2: User exports Gemini conversation</name>
  <action>
The user must manually export their Gemini coaching conversation. Claude cannot access the user's Gemini account.

Export the conversation to `data/gemini-export.txt`.
  </action>
  <instructions>
**Export your Gemini coaching mega-thread:**

1. Go to gemini.google.com and open the coaching conversation thread
2. Select all content in the thread (Ctrl+A or Cmd+A)
3. Copy and paste into a text file
4. Save as `data/gemini-export.txt` in the project root

**Alternative methods (if copy-paste doesn't capture everything):**
- Google Takeout: takeout.google.com -> select "Gemini Apps" -> export. Place the exported file in `data/`.
- Chrome extension "Gemini Chat Exporter": install, navigate to the thread, export as text.

**Quality check before continuing:**
- Open the file and verify the first workout session is present
- Scroll to the end and verify the most recent session is present
- Confirm AI responses are not cut off mid-sentence
  </instructions>
  <resume-signal>Type "exported" when data/gemini-export.txt is ready, or describe any issues with the export.</resume-signal>
</task>

<task type="auto">
  <name>Task 3: Build validation scripts and execute validation pipeline</name>
  <files>scripts/validate-export.ts, scripts/count-tokens.ts, scripts/test-chromadb.ts</files>
  <action>
Create three validation scripts. Run them in sequence after creation.

**Script 1: scripts/validate-export.ts (VALID-01 part 1)**
- Read `data/gemini-export.txt`
- Print file size (bytes and KB/MB)
- Print line count and approximate word count
- Attempt to detect conversation turn boundaries (look for patterns like "User:", "Model:", timestamps, or consistent delimiters)
- Print the first 500 characters and last 500 characters of the file for spot-checking
- Count estimated number of conversation turns (user messages)
- Output a quality assessment: PASS if file > 1KB and has detectable turn structure, WARN if structure unclear, FAIL if empty/tiny

**Script 2: scripts/count-tokens.ts (VALID-01 part 2 + VALID-03)**
- Load `data/gemini-export.txt`
- Use `@google/genai` SDK to call `ai.models.countTokens()` with model `gemini-2.5-flash`
- Print: total tokens, approximate word count, file size
- Apply RAG strategy decision framework:
  - < 100K tokens: "RECOMMENDATION: Context stuffing only. Fits easily in 1M window."
  - 100K-200K tokens: "RECOMMENDATION: Context stuffing + caching. Still fits, use caching to reduce cost."
  - 200K-500K tokens: "RECOMMENDATION: Hybrid (context stuffing + selective RAG). Approaching accuracy degradation zone."
  - > 500K tokens: "RECOMMENDATION: Full RAG required. Too large for reliable context stuffing."
- Print the recommendation prominently

**Script 3: scripts/test-chromadb.ts (VALID-02)**
- Start by checking ChromaDB server connectivity (try to reach http://localhost:8000/api/v2/heartbeat, print clear error if not running with instructions to start it: `npx chroma run --path ./chroma-data`)
- Create a ChromaClient pointing to `http://localhost:8000`
- Create a GoogleGeminiEmbeddingFunction using the API key from .env
- Create or get collection named `coaching-history-test`
- Add 3 sample workout coaching documents with metadata (date, type)
- Query the collection with "What was my squat workout like?" and print results
- Delete the test collection to clean up
- Then test Gemini structured JSON output:
  - Define a Zod schema for a workout (exercises array with name, sets, reps, weight, restSeconds; plus notes)
  - Call `ai.models.generateContent()` with `responseMimeType: 'application/json'` and the schema converted via `zodToJsonSchema()`
  - Parse the response with the Zod schema
  - Print the structured workout output
- Print "VALID-02: PASS" if both ChromaDB pipeline AND structured output work

All scripts should use `dotenv/config` import for env loading. Use `tsx` to run them: `npx tsx scripts/validate-export.ts`.

After creating all three scripts, run them in order:
1. `npx tsx scripts/validate-export.ts`
2. `npx tsx scripts/count-tokens.ts`
3. For script 3, first check if ChromaDB is running. If not, start it in the background: `npx chroma run --path ./chroma-data &` and wait a few seconds. Then run `npx tsx scripts/test-chromadb.ts`.

Capture all output for the summary.
  </action>
  <verify>
`npx tsx scripts/validate-export.ts` completes without errors and prints quality assessment.
`npx tsx scripts/count-tokens.ts` prints a token count and RAG strategy recommendation.
`npx tsx scripts/test-chromadb.ts` prints ChromaDB query results and a structured workout JSON, ending with "VALID-02: PASS".
  </verify>
  <done>
All three validation requirements resolved:
- VALID-01: Export validated and token count measured
- VALID-02: ChromaDB + Gemini embedding pipeline proven, structured JSON output verified
- VALID-03: RAG strategy decided based on measured token count
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `data/gemini-export.txt` exists and contains the coaching conversation
2. Token count is measured and printed (exact number known)
3. RAG strategy recommendation is documented (one of: context stuffing, caching, hybrid, full RAG)
4. ChromaDB successfully stored and retrieved documents using Gemini embeddings
5. Gemini structured output produced a valid workout JSON matching the Zod schema
6. All three VALID-XX requirements have concrete answers
</verification>

<success_criteria>
- Token count measurement exists (a specific number, not an estimate)
- RAG strategy is decided (one of the four options, with rationale)
- ChromaDB query returned semantically relevant results from sample data
- Structured JSON output from Gemini parsed successfully through Zod validation
- Export file quality verified (not truncated, turn structure detected)
</success_criteria>

<output>
After completion, create `.planning/phases/01-validation-and-foundation/01-01-SUMMARY.md`
</output>
